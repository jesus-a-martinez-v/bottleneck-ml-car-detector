{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Optimization\n",
    "\n",
    "In the previous notebook we decided to optimize the following models. \n",
    "\n",
    " - Rank=1, Name=**SVC-linear-0.4**, Score=**0.9877151685937721 (+/- 0.003806562050586554)**\n",
    " - Rank=4, Name=**PassiveAggressiveClassifier**, Score=**0.9873060780235428 (+/- 0.005755384960731155)**\n",
    " - Rank=11, Name=**SGDClassifier**, Score=**0.986486033144723 (+/- 0.005575110872674419)**\n",
    " - Rank=14, Name=**KNeighborsClassifier-1**, Score=**0.9833439566419908 (+/- 0.007040876080775306)**\n",
    " \n",
    "To optimize each model, we will use GridSearchCV, which is a method to automatically find the best parameters for a given model, based on a target metric, which, again, in this case is accuracy. \n",
    "\n",
    "The CV part means that we can use cross-validation to be really sure of the model's performance. As happened in the Model Evaluation phase, we cross-validate using 10 folds. \n",
    "\n",
    "As we might expect, this process will take some time, because we are training lots of models, and each variation will be spawn another ten models (due to the cross-validaton process).\n",
    "\n",
    "Let's get started defining the helper functions we'll use to optimize.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "This function will give us the relevant data needed to perform the optimization of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset():\n",
    "    X = np.load('global_max_features.npy')\n",
    "    y = np.load('labels.npy')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "This function returns a dict of dicts that contain the model to be optimized and the grid of parameters to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def define_models(models=dict()):\n",
    "    models['SGDClassifier'] = {\n",
    "        'model': SGDClassifier(),\n",
    "        'parameters': {\n",
    "            'loss': ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'),\n",
    "            'penalty': ('none','l2', 'l1'),\n",
    "            'alpha': (1e-3, 5e-3, 1e-4, 1e-2, 5e-3),\n",
    "            'fit_intercept': (True, False)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    models['KNeighborsClassifier-1'] = {\n",
    "        'model': KNeighborsClassifier(n_neighbors=1),\n",
    "        'parameters': {\n",
    "            'weights': ('uniform', 'distance'),\n",
    "            'algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    models['SVC-linear-0.4'] = {\n",
    "        'model': SVC(kernel='linear', C=0.4),\n",
    "        'parameters': {\n",
    "            'probability': (True, False),\n",
    "            'decision_function_shape': ('ovo', 'ovr'),\n",
    "            'shrinking': (True, False)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    models['PassiveAggressiveClassifier'] = {\n",
    "        'model': PassiveAggressiveClassifier(),\n",
    "        'parameters': {\n",
    "            'fit_intercept': (True, False),\n",
    "            'C': (1, 0.1, 0.01, 1.5, 2),\n",
    "            'loss': ('hinge', 'squared_hinge')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f'Defined {len(models)} models.')\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "As in the last notebook, this pipeline is used to pre-process the features that'll be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def make_pipeline(model):\n",
    "    steps = [\n",
    "        ('StandardScaler', StandardScaler()),\n",
    "        ('MinMaxScaler', MinMaxScaler()),\n",
    "        ('model', model)\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Here we are defining a couple of auxiliary functions that will perform the actual grid search for each model. At the end of the process, the parameters that yield the best estimator will be printed, along with the best score of this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search_model(X, y, model, folds, metric):\n",
    "    m = model['model'] \n",
    "    parameters = model['parameters']\n",
    "    \n",
    "    classifier = GridSearchCV(m, parameters, cv=folds, scoring=metric, n_jobs=-1)\n",
    "    pipeline = make_pipeline(classifier)\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    return pipeline.steps[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def grid_search_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        for model_name, model in models.items():\n",
    "            m = grid_search_model(X, y, model, folds, metric)\n",
    "\n",
    "            if m is not None:\n",
    "                print(f'Best parameters for {model_name}: \\n{m.best_params_}')\n",
    "                print(f'Best model {metric}: {m.best_score_ * 100}%')\n",
    "            else:\n",
    "                print(f'{model_name}: error')\n",
    "            \n",
    "            print('----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 4 models.\n",
      "Best parameters for SGDClassifier: \n",
      "{'alpha': 0.001, 'fit_intercept': False, 'loss': 'modified_huber', 'penalty': 'l2'}\n",
      "Best model accuracy: 98.7849829351536%\n",
      "----\n",
      "\n",
      "Best parameters for KNeighborsClassifier-1: \n",
      "{'algorithm': 'auto', 'weights': 'uniform'}\n",
      "Best model accuracy: 98.30716723549489%\n",
      "----\n",
      "\n",
      "Best parameters for SVC-linear-0.4: \n",
      "{'decision_function_shape': 'ovo', 'probability': True, 'shrinking': True}\n",
      "Best model accuracy: 98.7849829351536%\n",
      "----\n",
      "\n",
      "Best parameters for PassiveAggressiveClassifier: \n",
      "{'C': 2, 'fit_intercept': False, 'loss': 'squared_hinge'}\n",
      "Best model accuracy: 98.75767918088737%\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset()\n",
    "models = define_models()\n",
    "grid_search_models(X, y, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "These are our results:\n",
    "\n",
    " - **SVC-linear-0.4** goes from 98.77151685937721% to 98.7849829351536%, with a total improvement of 0.013466075776378261%.\n",
    " - **PassiveAggressiveClassifier** goes from 98.73060780235428% to 98.75767918088737%, with a total improvement of 0.027071378533079837%.\n",
    " - **SGDClassifier** goes from 98.6486033144723% to 98.7849829351536%, with a total improvement of 0.1363796206812964%.\n",
    " - **KNeighborsClassifier-1** goes from 98.33439566419908% to 98.30716723549489%, with a total worsening of 0.027228428704191288%.\n",
    " \n",
    "We see that, besides KNeighborsClassifier-1, all the models present, at least, a small improvement in their accuracy, which means that the grid search was successful.\n",
    "\n",
    "Clearly, the model that benefited the most was SGDClassifier, with a total improvement of 0.1363796206812964%. It also achieves the best score, tied with SVC-linear-0.4.\n",
    "\n",
    "Sadly, KNeighborsClassifier-1 do worse after the grid search. Maybe tweaking other parameters or adding more neighbors would yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    " - Try different models.\n",
    " - Try more parameters.\n",
    " - Try dimensionality reduction.\n",
    " - Use more feature engineering techniques.\n",
    " - Use stacking.\n",
    " \n",
    "### A final note\n",
    "\n",
    "We didn't use the flattened version of the data because it didn't fit in my computer's memory! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
