{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extracción de _Features_ Cuello de Botella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las ventajas más grandes de _transfer learnning_ es que nos permite aprovechar la enorme cantidad de conocimiento almacenado en las capas de los modelos pre-entrenados a nuestra disposición. En un mundo donde obtener data es muy costoso tanto en tiempo como en dinero, esta característica es bastante atractiva.\n",
    "\n",
    "Si pensamos al respecto, esto modelos pre-entrenados pueden servir como excelentes extractores de _features_, si decidimos deshacernos de sus últimas capas (las cuales tienen a ser redes totalmente conectadas usadas para clasificar imágenes en ImageNet).\n",
    "\n",
    "Con estos _features_ en mano, podemos anexar _cualquier_ modelo de machine learning, incluyendo (más no limitados a) redes neuronales, siempre y cuando llevemos a cabo las debidas transformaciones requeridas por el algoritmo receptor.\n",
    "\n",
    "Los _features_ resultantes de esta metodología se conocen como __features cuello de botella__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractores de _Features_\n",
    "\n",
    "Aunque cualquier modelo pre-entranado puede actuar como un extractor de _features_, en [este](https://github.com/jesus-a-martinez-v/deep-learning-car-detector) proyecto determinamos que el que mejor funciona para este problema es VGG16, por lo que es lógico reutilizarlo para este experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos tres extractores:\n",
    "\n",
    "  - **Global Average Pooling Extractor**: Para este extractor estamos aplicando la operación GlobalAveragePooling2D a las salidas del modelo pre-entrenado (sin las capas superiores). Una agrupación global promediada calcula, como su nombre lo indica, el promedio de los valores en un _feature map_ o kernel. Por tanto, si tenemos un volumen de _features_ con 32 filtros de 64x64, obtendremos un vector de 32 elementos.\n",
    "  - **Global Max Pooling Extractor**: Para este extractor estamos aplicando la operación GlobalMaxPooling2D a las salidas del modelo pre-entrenado (sin las capas superiores). Una agrupación global maximizada calcula, como su nombre lo indica, el máximo de los valores en un _feature map_ o kernel. Por tanto, si tenemos un volumen de _features_ con 32 filtros de 64x64, obtendremos un vector de 32 elementos.\n",
    "  - **Flatten Extractor**: Este es el extractor más simple, puesto que sólo reagrupa las salidas del modelo (sin las capas superiores) en un vector muy largo. Así, por ejemplo, para un volumen de _features_ de 32 filtros de 64x64, el resultado será un vector de 64 * 32 * 32 = 65536 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPool2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "x = base.output\n",
    "out = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "global_average_feature_extractor = Model(inputs=base.input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.output\n",
    "out = GlobalMaxPool2D()(x)\n",
    "        \n",
    "global_max_feature_extractor = Model(inputs=base.input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base.output\n",
    "out = Flatten()(x)\n",
    "        \n",
    "flatten_feature_extractor = Model(inputs=base.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones del Conjunto de Datos\n",
    "\n",
    "Con estos extractores definidos, podemos usarlos para generar nuevas versiones, transformaciones del conjunto de datos original. Nuestra meta con este projecto es utilizar deep learning para producir _features_ útiles para algoritmos más clásicos, como árboles de decisión o SVMs.\n",
    "\n",
    "Las imágenes originales pasarán por cada extractor, y los _features_ y etiquetas se almacenarán en archivos `.npy`, el cual es un formato del agrado de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares\n",
    "\n",
    "Estas dos funciones nos permitirán cargar una imagen, volverla un tensor y pre-procesarla de la manera que VGG16 espera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def path_to_tensor(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(image_paths):\n",
    "    tensors = [path_to_tensor(image_path) for image_path in image_paths]\n",
    "    return np.vstack(tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de transformar todos los datos, asegurémonos de que las cosas funcionan como deberían. Para ello, usaremos sólo unas cuantas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 3\n",
    "\n",
    "image_paths = glob('dataset/train/*/*')\n",
    "image_paths = random.sample(image_paths, SAMPLE_SIZE)\n",
    "\n",
    "# Calculate the image input\n",
    "image_input = preprocess_input(paths_to_tensor(image_paths))\n",
    "\n",
    "print(image_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esas dimensiones de arriba corresponden al lote que pasaremos a cada extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottlenecked batch shape (Global Max): (3, 512)\n",
      "Bottlenecked batch shape (Global Average): (3, 512)\n",
      "Bottlenecked batch shape (Flatten): (3, 25088)\n"
     ]
    }
   ],
   "source": [
    "global_max_bottlenecked_batch = global_max_feature_extractor.predict(image_input)\n",
    "print(f'Bottlenecked batch shape (Global Max): {global_max_bottlenecked_batch.shape}')\n",
    "\n",
    "global_average_bottlenecked_batch = global_average_feature_extractor.predict(image_input)\n",
    "print(f'Bottlenecked batch shape (Global Average): {global_average_bottlenecked_batch.shape}')\n",
    "\n",
    "flatten_bottlenecked_batch = flatten_feature_extractor.predict(image_input)\n",
    "print(f'Bottlenecked batch shape (Flatten): {flatten_bottlenecked_batch.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos apreciar que el Flatten Extractor, como esperábamos, es el que produce la representación más larga de las imánges de entrada, puesto que su operación no resume la información contenida en ellas, a diferencia de los otros dos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando las Tres Versiones de los Datos\n",
    "\n",
    "¡Estamos listos! ¡Generemos las transformaciones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7325, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if not Path('features.npy').is_file():\n",
    "    vehicles_images_path = glob('data/vehicles/*/*.png')\n",
    "    non_vehicles_images_path = glob('data/non-vehicles/*/*.png')\n",
    "\n",
    "    vehicles_images = preprocess_input(paths_to_tensor(vehicles_images_path))\n",
    "    non_vehicles_images = preprocess_input(paths_to_tensor(non_vehicles_images_path))\n",
    "\n",
    "    features = np.vstack([vehicles_images, non_vehicles_images])\n",
    "\n",
    "    np.save('features.npy', features)\n",
    "else:\n",
    "    features = np.load('features.npy')\n",
    "    \n",
    "print(f'Features shape: {features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (7325,)\n"
     ]
    }
   ],
   "source": [
    "if not Path('labels.npy').is_file():\n",
    "    vehicles_labels = np.array([1] * len(vehicles_images_path))\n",
    "    non_vehicles_labels = np.array([0] * len(non_vehicles_images_path))\n",
    "    labels = np.hstack([vehicles_labels, non_vehicles_labels])\n",
    "    \n",
    "    np.save('labels.npy', labels)\n",
    "else:\n",
    "    labels = np.load('labels.npy')\n",
    "\n",
    "    print(f'Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_average_features shape: (7325, 512)\n"
     ]
    }
   ],
   "source": [
    "if not Path('global_average_features.npy').is_file():\n",
    "    global_average_bottlenecked_features = global_average_feature_extractor.predict(features)\n",
    "    \n",
    "    np.save('global_average_features.npy', global_average_bottlenecked_features)\n",
    "else:\n",
    "    global_average_bottlenecked_features = np.load('global_average_features.npy')\n",
    "\n",
    "print(f'global_average_features shape: {global_average_bottlenecked_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_max_bottlenecked_features shape: (7325, 512)\n"
     ]
    }
   ],
   "source": [
    "if not Path('global_max_features.npy').is_file():\n",
    "    global_max_bottlenecked_features = global_max_feature_extractor.predict(features)\n",
    "    np.save('global_max_features.npy', global_max_bottlenecked_features)\n",
    "else:\n",
    "    global_max_bottlenecked_features = np.load('global_max_features.npy')\n",
    "\n",
    "print(f'global_max_bottlenecked_features shape: {global_max_bottlenecked_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened_bottlenecked_features shape: (7325, 25088)\n"
     ]
    }
   ],
   "source": [
    "if not Path('flattened_features.npy').is_file():\n",
    "    flattened_bottlenecked_features = flatten_feature_extractor.predict(features)\n",
    "    np.save('flattened_features.npy', flattened_bottlenecked_features)\n",
    "else:\n",
    "    flattened_bottlenecked_features = np.load('flattened_features.npy')\n",
    "\n",
    "print(f'flattened_bottlenecked_features shape: {flattened_bottlenecked_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas versiones de los datos podemos ahora pasar al proceso de evaluar diferentes algoritmos con cada una de ellas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
