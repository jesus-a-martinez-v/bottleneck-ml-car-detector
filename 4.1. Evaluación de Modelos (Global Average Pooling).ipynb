{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Evaluación de Modelos (Global Average Pooling)\n",
    "\n",
    "Ahora que nos hemos familiarizado con nuestros datos, el próximo paso lógico es explorar el espacio de los algoritmos que eventualmente producirán un buen modelo para la tarea que buscamos resolver.\n",
    "\n",
    "Nuestra meta en este notebook no es desarrollar una solución vanguardista, sino, más bien, revisar diversas arquitecturas con el fin de ver cuáles serán promovidas a la siguiente etapa del proceso, centrada en la optimización.\n",
    "\n",
    "Sin más preámbulos, pongámonos manos a la obra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión\n",
    "\n",
    "Para evaluar un amplio espectro de posibles algoritmos, necesitamos primero implementar algunos métodos. Empecemos por darle forma a la data que usaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "Esta función nos dará la data relevante para el experimento en este notebook, la cual corresponde a los _features_ generados por el Global Average Pooling Extractor. Notemos que estamos cargando los _features_ guardados en disco en formato `.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset():\n",
    "    X = np.load('global_average_features.npy')\n",
    "    y = np.load('labels.npy')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos\n",
    "\n",
    "Esta función retorna un amplio rango de modelos, desde lineales como _logistic regression_, a otros basados en árboles como _extra trees_ e, incluso, _ensembles_, como AdaBoost. También estaremos usando un par de versiones diferentes del mismo modelo subyacente, como en el caso de KNeighborsClassifier, donde creamos diferentes instancias para distintos números de vecinos (empezando 1 hasta 25).\n",
    "\n",
    "Es importante mencionar que crearemos estos modelos con los valores por defectors para darles una oportunidad justa de resolver el problema. La optimización vendrá luego para aquellos modelos que sean prometedores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def define_models(models=dict()):\n",
    "    models['LogisticRegression'] = LogisticRegression()\n",
    "    models['SGDClassifier'] = SGDClassifier()\n",
    "    models['PassiveAggressiveClassifier'] = PassiveAggressiveClassifier()\n",
    "    models['DecisionTreeClassifier'] = DecisionTreeClassifier()\n",
    "    models['ExtraTreeClassifier'] = ExtraTreeClassifier()\n",
    "    \n",
    "    number_of_trees = 100\n",
    "    models[f'AdaBoostClassifier-{number_of_trees}'] = AdaBoostClassifier(n_estimators=number_of_trees)\n",
    "    models[f'BaggingClassifier-{number_of_trees}'] = BaggingClassifier(n_estimators=number_of_trees)\n",
    "    models[f'RandomForestClassifier-{number_of_trees}'] = RandomForestClassifier(n_estimators=number_of_trees)\n",
    "    models[f'ExtraTreesClassifier-{number_of_trees}'] = ExtraTreesClassifier(n_estimators=number_of_trees)\n",
    "    models[f'GradientBoostingClassifier-{number_of_trees}'] = GradientBoostingClassifier(n_estimators=number_of_trees)\n",
    "    6\n",
    "    number_of_neighbors = range(1, 25)\n",
    "    for n in number_of_neighbors:\n",
    "        models[f'KNeighborsClassifier-{n}'] = KNeighborsClassifier(n_neighbors=n)\n",
    "        \n",
    "    kernels = {'linear', 'poly'}\n",
    "    cs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for kernel in kernels:\n",
    "        for c in cs:\n",
    "            models[f'SCV-{kernel}-{c}'] = SVC(kernel=kernel, C=c)\n",
    "        \n",
    "    alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for alpha in alphas:\n",
    "        models[f'RidgeClassifier-{alpha}'] = RidgeClassifier(alpha=alpha)\n",
    "    \n",
    "    print(f'Defined {len(models)} models.')\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Un _pipeline_ es simplemente un proceso donde vamos transformando los datos en cada paso del mismo. En este caso, usaremos un _pipeline_ para pre-procesar la data que le pasaremos a los modelos. En particular, estamos escalando y estandarizando cada _feature_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def make_pipeline(model):\n",
    "    steps = [\n",
    "        ('StandardScaler', StandardScaler()),\n",
    "        ('MinMaxScaler', MinMaxScaler()),\n",
    "        ('model', model)\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando un Modelo\n",
    "\n",
    "Para estar realmente seguros de que nuestro modelo está aprendiendo, usaremos K-Fold Cross-Validation, una técnica la cual, básicamente, entrena K modelos, donde K-1 pedazos de los datos serán utilizados para entrenar, mientras que el pedazo restante para probar. Lo bueno es que mediante este procedimiento utilizados todos los datos para entrenar **y** todos los datos para probar, eventualmente.\n",
    "\n",
    "Puesto que sólo estamos interesados en determinar rápidamente que modelos tienen potencial, apagaremos los _warnings_ en la función `robust_evaluate_model`.\n",
    "\n",
    "`evaluate_models` evalua un modelo y luego produce una mpetrica consolidada, la cual es el promedio de la exactitud (_accuracy_). También imprime esta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "    pipeline = make_pipeline(model)\n",
    "    \n",
    "    return cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore')\n",
    "            return evaluate_model(X, y, model, folds, metric)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        \n",
    "        if scores is not None:\n",
    "            results[model_name] = scores\n",
    "            mean_score, std_score = np.mean(scores), np.std(scores)\n",
    "            print(f'{model_name}: {mean_score * 100}% (+/- {std_score})')\n",
    "        else:\n",
    "            print(f'{model_name}: error')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen\n",
    "\n",
    "Tener todos los datos necesarios a disposición es importante para tomar una decisión. Esta es la misión de la función `summarize_results`. Devuelve los N mejores modelos en términos de desempeño. También produce, opcionalmente, un _box-plot_ para una referencia visualmente más atractiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def summarize_results(results, maximize=True, top_n=10, plot=True):\n",
    "    if len(results) == 0:\n",
    "        print('No results')\n",
    "        return\n",
    "    \n",
    "    n = min(top_n, len(results))\n",
    "    mean_scores = sorted([(key, np.mean(value)) for key, value in results.items()], key=lambda p: p[1])\n",
    "    \n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "        \n",
    "    names = [mean_score[0] for mean_score in mean_scores[:n]]\n",
    "    scores = [results[mean_score[0]] for mean_score in mean_scores[:n]]\n",
    "    \n",
    "    print('--------')\n",
    "    for index in range(n):\n",
    "        name = names[index]\n",
    "        mean_score, std_score = np.mean(results[name]), np.std(results[name])\n",
    "        print(f'Rank={index + 1}, Name={name}, Score={mean_score} (+/- {std_score})')\n",
    "        \n",
    "    if plot:\n",
    "        plt.boxplot(scores, labels=names)\n",
    "        _, labels = plt.xticks()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Manos a la Obra!\n",
    "\n",
    "Estamos listos. ¡Hora de poner a prueba a los candidatos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 64 models.\n",
      "LogisticRegression: 99.08555677319795% (+/- 0.005723329990001992)\n",
      "SGDClassifier: 99.16728170032577% (+/- 0.004665749258440611)\n",
      "PassiveAggressiveClassifier: 98.33512252215984% (+/- 0.014067414035578138)\n",
      "DecisionTreeClassifier: 95.0306584960377% (+/- 0.016767490056210116)\n",
      "ExtraTreeClassifier: 90.21200023855852% (+/- 0.018233629331836067)\n",
      "AdaBoostClassifier-100: 98.66218996712364% (+/- 0.005556565905637869)\n",
      "BaggingClassifier-100: 97.66548132906911% (+/- 0.0132498069048328)\n",
      "RandomForestClassifier-100: 98.06173074199152% (+/- 0.009149486997719558)\n",
      "ExtraTreesClassifier-100: 98.28021679004615% (+/- 0.007221861443082485)\n",
      "GradientBoostingClassifier-100: 98.3756774688942% (+/- 0.008554217473921419)\n",
      "KNeighborsClassifier-1: 98.88041509180775% (+/- 0.006880231057879147)\n",
      "KNeighborsClassifier-2: 98.77133048554111% (+/- 0.00521682428326239)\n",
      "KNeighborsClassifier-3: 98.98979789621215% (+/- 0.005571132338542561)\n",
      "KNeighborsClassifier-4: 98.92162234696843% (+/- 0.00614647322899209)\n",
      "KNeighborsClassifier-5: 98.90796114478266% (+/- 0.006013163795695108)\n",
      "KNeighborsClassifier-6: 98.77146094722639% (+/- 0.006401002755918868)\n",
      "KNeighborsClassifier-7: 98.86695890084167% (+/- 0.00637629685715222)\n",
      "KNeighborsClassifier-8: 98.75783701980781% (+/- 0.006724798514552489)\n",
      "KNeighborsClassifier-9: 98.64865922662312% (+/- 0.007873261226417896)\n",
      "KNeighborsClassifier-10: 98.60773153221659% (+/- 0.008383951480837362)\n",
      "KNeighborsClassifier-11: 98.64867786400676% (+/- 0.008530795695540707)\n",
      "KNeighborsClassifier-12: 98.6077874443674% (+/- 0.009106159527030202)\n",
      "KNeighborsClassifier-13: 98.59412624218163% (+/- 0.009433500232635068)\n",
      "KNeighborsClassifier-14: 98.60782471913463% (+/- 0.009623235785024966)\n",
      "KNeighborsClassifier-15: 98.62143000916959% (+/- 0.008851048915843448)\n",
      "KNeighborsClassifier-16: 98.6214486465532% (+/- 0.008996279858140112)\n",
      "KNeighborsClassifier-17: 98.58052095214666% (+/- 0.00909366977655662)\n",
      "KNeighborsClassifier-18: 98.55323582254229% (+/- 0.009934715470483173)\n",
      "KNeighborsClassifier-19: 98.53955598297289% (+/- 0.009432507902740219)\n",
      "KNeighborsClassifier-20: 98.51227085336852% (+/- 0.009673840497186413)\n",
      "KNeighborsClassifier-21: 98.51228949075212% (+/- 0.009731123602439539)\n",
      "KNeighborsClassifier-22: 98.47134315896197% (+/- 0.009622480415791798)\n",
      "KNeighborsClassifier-23: 98.45768195677618% (+/- 0.009608121867490039)\n",
      "KNeighborsClassifier-24: 98.40309306018385% (+/- 0.01037207327197409)\n",
      "SCV-linear-0.1: 98.94900066349084% (+/- 0.006101602035411863)\n",
      "SCV-linear-0.2: 99.15371368505802% (+/- 0.004474483442540483)\n",
      "SCV-linear-0.3: 99.23558771125475% (+/- 0.003515026977485452)\n",
      "SCV-linear-0.4: 99.2628542034755% (+/- 0.003062619363378767)\n",
      "SCV-linear-0.5: 99.30381917264926% (+/- 0.0032537779494845823)\n",
      "SCV-linear-0.6: 99.34476550443941% (+/- 0.0034405415852301552)\n",
      "SCV-linear-0.7: 99.34478414182303% (+/- 0.0037011376799861427)\n",
      "SCV-linear-0.8: 99.34478414182303% (+/- 0.0037011376799861427)\n",
      "SCV-linear-0.9: 99.34480277920666% (+/- 0.003944167917138149)\n",
      "SCV-linear-1.0: 99.34480277920666% (+/- 0.003944167917138149)\n",
      "SCV-poly-0.1: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.2: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.3: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.4: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.5: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.6: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.7: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.8: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.9: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-1.0: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "RidgeClassifier-0.1: 99.04449861710614% (+/- 0.0044840897996343745)\n",
      "RidgeClassifier-0.2: 99.05814118190831% (+/- 0.004544032566178253)\n",
      "RidgeClassifier-0.3: 99.07180238409413% (+/- 0.0046393208404255535)\n",
      "RidgeClassifier-0.4: 99.08544494889628% (+/- 0.0044865102324409545)\n",
      "RidgeClassifier-0.5: 99.09908751369848% (+/- 0.0045749821036690985)\n",
      "RidgeClassifier-0.6: 99.08542631151269% (+/- 0.0044866407127618696)\n",
      "RidgeClassifier-0.7: 99.11273007850066% (+/- 0.004452821838333735)\n",
      "RidgeClassifier-0.8: 99.12639128068645% (+/- 0.004574692652304791)\n",
      "RidgeClassifier-0.9: 99.11274871588427% (+/- 0.004657207420451205)\n",
      "RidgeClassifier-1.0: 99.11274871588427% (+/- 0.004657207420451205)\n",
      "--------\n",
      "Rank=1, Name=SCV-linear-1.0, Score=0.9934480277920665 (+/- 0.003944167917138149)\n",
      "Rank=2, Name=SCV-linear-0.9, Score=0.9934480277920665 (+/- 0.003944167917138149)\n",
      "Rank=3, Name=SCV-linear-0.8, Score=0.9934478414182303 (+/- 0.0037011376799861427)\n",
      "Rank=4, Name=SCV-linear-0.7, Score=0.9934478414182303 (+/- 0.0037011376799861427)\n",
      "Rank=5, Name=SCV-linear-0.6, Score=0.9934476550443941 (+/- 0.0034405415852301552)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63c22dff98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_dataset()\n",
    "models = define_models()\n",
    "results = evaluate_models(X, y, models)\n",
    "summarize_results(results, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo para tener un ranking de todos los modelos, llamemos nuevamente a la función `summarize_results` pero desactivando la opción de graficar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Rank=1, Name=SCV-linear-1.0, Score=0.9934480277920665 (+/- 0.003944167917138149)\n",
      "Rank=2, Name=SCV-linear-0.9, Score=0.9934480277920665 (+/- 0.003944167917138149)\n",
      "Rank=3, Name=SCV-linear-0.8, Score=0.9934478414182303 (+/- 0.0037011376799861427)\n",
      "Rank=4, Name=SCV-linear-0.7, Score=0.9934478414182303 (+/- 0.0037011376799861427)\n",
      "Rank=5, Name=SCV-linear-0.6, Score=0.9934476550443941 (+/- 0.0034405415852301552)\n",
      "Rank=6, Name=SCV-linear-0.5, Score=0.9930381917264925 (+/- 0.0032537779494845823)\n",
      "Rank=7, Name=SCV-linear-0.4, Score=0.9926285420347549 (+/- 0.003062619363378767)\n",
      "Rank=8, Name=SCV-linear-0.3, Score=0.9923558771125475 (+/- 0.003515026977485452)\n",
      "Rank=9, Name=SGDClassifier, Score=0.9916728170032577 (+/- 0.004665749258440611)\n",
      "Rank=10, Name=SCV-linear-0.2, Score=0.9915371368505802 (+/- 0.004474483442540483)\n",
      "Rank=11, Name=RidgeClassifier-0.8, Score=0.9912639128068644 (+/- 0.004574692652304791)\n",
      "Rank=12, Name=RidgeClassifier-1.0, Score=0.9911274871588427 (+/- 0.004657207420451205)\n",
      "Rank=13, Name=RidgeClassifier-0.9, Score=0.9911274871588427 (+/- 0.004657207420451205)\n",
      "Rank=14, Name=RidgeClassifier-0.7, Score=0.9911273007850065 (+/- 0.004452821838333735)\n",
      "Rank=15, Name=RidgeClassifier-0.5, Score=0.9909908751369848 (+/- 0.0045749821036690985)\n",
      "Rank=16, Name=LogisticRegression, Score=0.9908555677319795 (+/- 0.005723329990001992)\n",
      "Rank=17, Name=RidgeClassifier-0.4, Score=0.9908544494889628 (+/- 0.0044865102324409545)\n",
      "Rank=18, Name=RidgeClassifier-0.6, Score=0.9908542631151269 (+/- 0.0044866407127618696)\n",
      "Rank=19, Name=RidgeClassifier-0.3, Score=0.9907180238409412 (+/- 0.0046393208404255535)\n",
      "Rank=20, Name=RidgeClassifier-0.2, Score=0.9905814118190831 (+/- 0.004544032566178253)\n",
      "Rank=21, Name=RidgeClassifier-0.1, Score=0.9904449861710614 (+/- 0.0044840897996343745)\n",
      "Rank=22, Name=KNeighborsClassifier-3, Score=0.9898979789621215 (+/- 0.005571132338542561)\n",
      "Rank=23, Name=SCV-linear-0.1, Score=0.9894900066349084 (+/- 0.006101602035411863)\n",
      "Rank=24, Name=KNeighborsClassifier-4, Score=0.9892162234696844 (+/- 0.00614647322899209)\n",
      "Rank=25, Name=KNeighborsClassifier-5, Score=0.9890796114478266 (+/- 0.006013163795695108)\n",
      "Rank=26, Name=KNeighborsClassifier-1, Score=0.9888041509180775 (+/- 0.006880231057879147)\n",
      "Rank=27, Name=KNeighborsClassifier-7, Score=0.9886695890084167 (+/- 0.00637629685715222)\n",
      "Rank=28, Name=KNeighborsClassifier-6, Score=0.9877146094722639 (+/- 0.006401002755918868)\n",
      "Rank=29, Name=KNeighborsClassifier-2, Score=0.9877133048554112 (+/- 0.00521682428326239)\n",
      "Rank=30, Name=KNeighborsClassifier-8, Score=0.9875783701980781 (+/- 0.006724798514552489)\n",
      "Rank=31, Name=AdaBoostClassifier-100, Score=0.9866218996712364 (+/- 0.005556565905637869)\n",
      "Rank=32, Name=KNeighborsClassifier-11, Score=0.9864867786400675 (+/- 0.008530795695540707)\n",
      "Rank=33, Name=KNeighborsClassifier-9, Score=0.9864865922662313 (+/- 0.007873261226417896)\n",
      "Rank=34, Name=KNeighborsClassifier-16, Score=0.986214486465532 (+/- 0.008996279858140112)\n",
      "Rank=35, Name=KNeighborsClassifier-15, Score=0.9862143000916959 (+/- 0.008851048915843448)\n",
      "Rank=36, Name=KNeighborsClassifier-14, Score=0.9860782471913463 (+/- 0.009623235785024966)\n",
      "Rank=37, Name=KNeighborsClassifier-12, Score=0.986077874443674 (+/- 0.009106159527030202)\n",
      "Rank=38, Name=KNeighborsClassifier-10, Score=0.9860773153221659 (+/- 0.008383951480837362)\n",
      "Rank=39, Name=KNeighborsClassifier-13, Score=0.9859412624218162 (+/- 0.009433500232635068)\n",
      "Rank=40, Name=KNeighborsClassifier-17, Score=0.9858052095214666 (+/- 0.00909366977655662)\n",
      "Rank=41, Name=KNeighborsClassifier-18, Score=0.985532358225423 (+/- 0.009934715470483173)\n",
      "Rank=42, Name=KNeighborsClassifier-19, Score=0.9853955598297288 (+/- 0.009432507902740219)\n",
      "Rank=43, Name=KNeighborsClassifier-21, Score=0.9851228949075213 (+/- 0.009731123602439539)\n",
      "Rank=44, Name=KNeighborsClassifier-20, Score=0.9851227085336852 (+/- 0.009673840497186413)\n",
      "Rank=45, Name=KNeighborsClassifier-22, Score=0.9847134315896197 (+/- 0.009622480415791798)\n",
      "Rank=46, Name=KNeighborsClassifier-23, Score=0.9845768195677618 (+/- 0.009608121867490039)\n",
      "Rank=47, Name=KNeighborsClassifier-24, Score=0.9840309306018385 (+/- 0.01037207327197409)\n",
      "Rank=48, Name=GradientBoostingClassifier-100, Score=0.983756774688942 (+/- 0.008554217473921419)\n",
      "Rank=49, Name=PassiveAggressiveClassifier, Score=0.9833512252215983 (+/- 0.014067414035578138)\n",
      "Rank=50, Name=ExtraTreesClassifier-100, Score=0.9828021679004616 (+/- 0.007221861443082485)\n",
      "Rank=51, Name=RandomForestClassifier-100, Score=0.9806173074199153 (+/- 0.009149486997719558)\n",
      "Rank=52, Name=BaggingClassifier-100, Score=0.976654813290691 (+/- 0.0132498069048328)\n",
      "Rank=53, Name=DecisionTreeClassifier, Score=0.950306584960377 (+/- 0.016767490056210116)\n",
      "Rank=54, Name=ExtraTreeClassifier, Score=0.9021200023855851 (+/- 0.018233629331836067)\n",
      "Rank=55, Name=SCV-poly-1.0, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=56, Name=SCV-poly-0.9, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=57, Name=SCV-poly-0.8, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=58, Name=SCV-poly-0.7, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=59, Name=SCV-poly-0.6, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=60, Name=SCV-poly-0.5, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=61, Name=SCV-poly-0.4, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=62, Name=SCV-poly-0.3, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=63, Name=SCV-poly-0.2, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n",
      "Rank=64, Name=SCV-poly-0.1, Score=0.5324234562655155 (+/- 0.00036342898038604915)\n"
     ]
    }
   ],
   "source": [
    "summarize_results(results, top_n=len(results), plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Entrenamos cada modelo usando el _framework_ descrito en las celdas anteriores para determinar el poder de aprendizaje de cada uno.\n",
    "\n",
    "Es notable que SVC se desempeña terribelemente mal cuando utiliza un kernel polinómico, en vez de uno lineal.\n",
    "\n",
    "Debemos destacar que los modelos que mejor lo hacen son variaciones de SVC con kernel lineal y diferentes valores de penalización (C).\n",
    "\n",
    "No obstante, en pos de la diversidad, promoveremos los siguientes cuatro modelos a la fase de optimización:\n",
    "\n",
    " - Rank=1, Name=**SVC-linear-1.0**, Score=**0.9934480277920665 (+/- 0.003944167917138149)**\n",
    " - Rank=9, Name=**SGDClassifier**, Score=**0.9916728170032577 (+/- 0.004665749258440611)**\n",
    " - Rank=11, Name=**RidgeClassifier-0.8**, Score=**0.9912639128068644 (+/- 0.004574692652304791)**\n",
    " - Rank=24, Name=**KNeighborsClassifier-4**, Score=**0.9892162234696844 (+/- 0.00614647322899209)**\n",
    " \n",
    "Debemos recordar que estos modelos ya están rindiendo bastante bien con nuestra selección inicial de parámetros, pero, de todas formas, intentaremos exprimirles la mayor cantidad de desempeño que podamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
