{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation (Global Average Pooling)\n",
    "\n",
    "We are now familiar with our data, so the next logical step is to explore the space of algorithms that will eventually yield a good model for the task we are trying to solve.\n",
    "\n",
    "Our goal in this notebook is not to develop state of the art solutions, but rather spot-check several architectures in order to see which will be promoted to the next phase of the process, centered around model optimization. \n",
    "\n",
    "Without further ado, let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-Checking\n",
    "\n",
    "In order to evaluate a broad range of possible algorithms, we need to implement some functions first. Let's start by shaping our data the way we need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "This function will give us the data relevant to the experiment in this notebook, which are the features generated by the Global Average Pooling Extractor. Notice we are just loading the resulting features saved to disk in `.npy` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset():\n",
    "    X = np.load('global_average_features.npy')\n",
    "    y = np.load('labels.npy')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "This function returns a wide range of models, from linear ones such as logistic regression, to tree based ones such as extra trees or even ensembles, like AdaBoost. We are also using a couple of different versions of the same underlying model, as in the case of KNeighborsClassifier, where we create a new instance for a different number of neighbors (starting at 1 up to 25)\n",
    "\n",
    "It is important to mention that we are creating these models with the default values just to give them a fair chance of solving the problem. The optimization will come later for those models that are promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def define_models(models=dict()):\n",
    "    models['LogisticRegression'] = LogisticRegression()\n",
    "    models['SGDClassifier'] = SGDClassifier()\n",
    "    models['PassiveAggressiveClassifier'] = PassiveAggressiveClassifier()\n",
    "    models['DecisionTreeClassifier'] = DecisionTreeClassifier()\n",
    "    models['ExtraTreeClassifier'] = ExtraTreeClassifier()\n",
    "    \n",
    "    number_of_trees = 100\n",
    "    models[f'AdaBoostClassifier-{number_of_trees}'] = AdaBoostClassifier(n_estimators=number_of_trees)\n",
    "    models[f'BaggingClassifier-{number_of_trees}'] = BaggingClassifier(n_estimators=number_of_trees)\n",
    "    models[f'RandomForestClassifier-{number_of_trees}'] = RandomForestClassifier(n_estimators=number_of_trees)\n",
    "    models[f'ExtraTreesClassifier-{number_of_trees}'] = ExtraTreesClassifier(n_estimators=number_of_trees)\n",
    "    models[f'GradientBoostingClassifier-{number_of_trees}'] = GradientBoostingClassifier(n_estimators=number_of_trees)\n",
    "    \n",
    "    number_of_neighbors = range(1, 25)\n",
    "    for n in number_of_neighbors:\n",
    "        models[f'KNeighborsClassifier-{n}'] = KNeighborsClassifier(n_neighbors=n)\n",
    "        \n",
    "    kernels = {'linear', 'poly'}\n",
    "    cs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for kernel in kernels:\n",
    "        for c in cs:\n",
    "            models[f'SCV-{kernel}-{c}'] = SVC(kernel=kernel, C=c)\n",
    "        \n",
    "    alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    for alpha in alphas:\n",
    "        models[f'RidgeClassifier-{alpha}'] = RidgeClassifier(alpha=alpha)\n",
    "    \n",
    "    print(f'Defined {len(models)} models.')\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 64 models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'SGDClassifier': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "        shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       " 'PassiveAggressiveClassifier': PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "               fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
       "               n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
       "               verbose=0, warm_start=False),\n",
       " 'DecisionTreeClassifier': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'ExtraTreeClassifier': ExtraTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, random_state=None,\n",
       "           splitter='random'),\n",
       " 'AdaBoostClassifier-100': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=100, random_state=None),\n",
       " 'BaggingClassifier-100': BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "          bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "          n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "          verbose=0, warm_start=False),\n",
       " 'RandomForestClassifier-100': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'ExtraTreesClassifier-100': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       " 'GradientBoostingClassifier-100': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False),\n",
       " 'KNeighborsClassifier-1': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-2': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-3': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-4': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-5': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-6': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-7': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-8': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-9': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-10': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-11': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-12': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-13': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-14': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=14, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-15': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-16': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=16, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-17': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-18': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-19': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=19, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-20': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-21': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=21, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-22': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=22, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-23': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=23, p=2,\n",
       "            weights='uniform'),\n",
       " 'KNeighborsClassifier-24': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
       "            weights='uniform'),\n",
       " 'SCV-poly-0.1': SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.2': SVC(C=0.2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.3': SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.4': SVC(C=0.4, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.5': SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.6': SVC(C=0.6, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.7': SVC(C=0.7, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.8': SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-0.9': SVC(C=0.9, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-poly-1.0': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.1': SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.2': SVC(C=0.2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.3': SVC(C=0.3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.4': SVC(C=0.4, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.5': SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.6': SVC(C=0.6, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.7': SVC(C=0.7, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.8': SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-0.9': SVC(C=0.9, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'SCV-linear-1.0': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'RidgeClassifier-0.1': RidgeClassifier(alpha=0.1, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.2': RidgeClassifier(alpha=0.2, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.3': RidgeClassifier(alpha=0.3, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.4': RidgeClassifier(alpha=0.4, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.5': RidgeClassifier(alpha=0.5, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.6': RidgeClassifier(alpha=0.6, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.7': RidgeClassifier(alpha=0.7, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.8': RidgeClassifier(alpha=0.8, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-0.9': RidgeClassifier(alpha=0.9, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001),\n",
       " 'RidgeClassifier-1.0': RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "         tol=0.001)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "A pipeline is just a process were we transform the data at each step. In this case, we are using a pipeline to pre-process the data that will be feed to a model. Particularly, we are scaling and standardizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def make_pipeline(model):\n",
    "    steps = [\n",
    "        ('StandardScaler', StandardScaler()),\n",
    "        ('MinMaxScaler', MinMaxScaler()),\n",
    "        ('model', model)\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Model\n",
    "\n",
    "To be really sure that our model is doing well, we are using K-Fold Cross-Validation, which, basically, trains K models, where K-1 chunks of the data are used for training purposes and the remaining one for testing. The cool part is that the chunk every piece of data is used for training **and** testing, eventually.\n",
    "\n",
    "Given that we are just interested in quickly determining which models are promising, we are shutting off the warning in the `robust_evaluate_model` function.\n",
    "\n",
    "The `evaluate_models` evaluates a model and then produces a consolidated metric, which is just the mean value of the metric of choice which, in this case, given the nature of the data, is the `accuracy`. It also prints this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "    pipeline = make_pipeline(model)\n",
    "    \n",
    "    return cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore')\n",
    "            return evaluate_model(X, y, model, folds, metric)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "    results = dict()\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        \n",
    "        if scores is not None:\n",
    "            results[model_name] = scores\n",
    "            mean_score, std_score = np.mean(scores), np.std(scores)\n",
    "            print(f'{model_name}: {mean_score * 100}% (+/- {std_score})')\n",
    "        else:\n",
    "            print(f'{model_name}: error')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "Having all the data required to make a decision in a single place is important. This is the mission of the `summarize_results` function. It returns the top N models, sorted by their performance in a descending order. It also produces (optionally) a handy box-plot for a more eye-appealing reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def summarize_results(results, maximize=True, top_n=10, plot=True):\n",
    "    if len(results) == 0:\n",
    "        print('No results')\n",
    "        return\n",
    "    \n",
    "    n = min(top_n, len(results))\n",
    "    mean_scores = [(key, np.mean(value)) for key, value in results.items()]\n",
    "    \n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "        \n",
    "    names = [mean_score[0] for mean_score in mean_scores[:n]]\n",
    "    scores = [results[mean_score[0]] for mean_score in mean_scores[:n]]\n",
    "    \n",
    "    print('--------')\n",
    "    for index in range(n):\n",
    "        name = names[index]\n",
    "        mean_score, std_score = np.mean(results[name]), np.std(results[name])\n",
    "        print(f'Rank={index + 1}, Name={name}, Score={mean_score} (+/- {std_score})')\n",
    "        \n",
    "    if plot:\n",
    "        plt.boxplot(scores, labels=names)\n",
    "        _, labels = plt.xticks()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off to the Races!\n",
    "\n",
    "We are all set. Let's spot-check these algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 64 models.\n",
      "LogisticRegression: 99.08555677319795% (+/- 0.005723329990001992)\n",
      "SGDClassifier: 99.20822803211594% (+/- 0.004086184200138183)\n",
      "PassiveAggressiveClassifier: 99.1399406585706% (+/- 0.004005637524980804)\n",
      "DecisionTreeClassifier: 95.05809272471092% (+/- 0.017586188075791997)\n",
      "ExtraTreeClassifier: 90.17129619275528% (+/- 0.02531214873616737)\n",
      "AdaBoostClassifier-100: 98.66218996712364% (+/- 0.005556565905637869)\n",
      "BaggingClassifier-100: 97.378857006538% (+/- 0.014322862612304149)\n",
      "RandomForestClassifier-100: 98.17100172209425% (+/- 0.008479558104220198)\n",
      "ExtraTreesClassifier-100: 98.19838003861665% (+/- 0.008577634211922352)\n",
      "GradientBoostingClassifier-100: 98.38932003369638% (+/- 0.00856196586660886)\n",
      "KNeighborsClassifier-1: 98.88041509180775% (+/- 0.006880231057879147)\n",
      "KNeighborsClassifier-2: 98.77133048554111% (+/- 0.00521682428326239)\n",
      "KNeighborsClassifier-3: 98.98979789621215% (+/- 0.005571132338542561)\n",
      "KNeighborsClassifier-4: 98.92162234696843% (+/- 0.00614647322899209)\n",
      "KNeighborsClassifier-5: 98.90796114478266% (+/- 0.006013163795695108)\n",
      "KNeighborsClassifier-6: 98.77146094722639% (+/- 0.006401002755918868)\n",
      "KNeighborsClassifier-7: 98.86695890084167% (+/- 0.00637629685715222)\n",
      "KNeighborsClassifier-8: 98.75783701980781% (+/- 0.006724798514552489)\n",
      "KNeighborsClassifier-9: 98.64865922662312% (+/- 0.007873261226417896)\n",
      "KNeighborsClassifier-10: 98.60773153221659% (+/- 0.008383951480837362)\n",
      "KNeighborsClassifier-11: 98.64867786400676% (+/- 0.008530795695540707)\n",
      "KNeighborsClassifier-12: 98.6077874443674% (+/- 0.009106159527030202)\n",
      "KNeighborsClassifier-13: 98.59412624218163% (+/- 0.009433500232635068)\n",
      "KNeighborsClassifier-14: 98.60782471913463% (+/- 0.009623235785024966)\n",
      "KNeighborsClassifier-15: 98.62143000916959% (+/- 0.008851048915843448)\n",
      "KNeighborsClassifier-16: 98.6214486465532% (+/- 0.008996279858140112)\n",
      "KNeighborsClassifier-17: 98.58052095214666% (+/- 0.00909366977655662)\n",
      "KNeighborsClassifier-18: 98.55323582254229% (+/- 0.009934715470483173)\n",
      "KNeighborsClassifier-19: 98.53955598297289% (+/- 0.009432507902740219)\n",
      "KNeighborsClassifier-20: 98.51227085336852% (+/- 0.009673840497186413)\n",
      "KNeighborsClassifier-21: 98.51228949075212% (+/- 0.009731123602439539)\n",
      "KNeighborsClassifier-22: 98.47134315896197% (+/- 0.009622480415791798)\n",
      "KNeighborsClassifier-23: 98.45768195677618% (+/- 0.009608121867490039)\n",
      "KNeighborsClassifier-24: 98.40309306018385% (+/- 0.01037207327197409)\n",
      "SCV-poly-0.1: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.2: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.3: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.4: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.5: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.6: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.7: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.8: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-0.9: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-poly-1.0: 53.24234562655155% (+/- 0.00036342898038604915)\n",
      "SCV-linear-0.1: 98.94900066349084% (+/- 0.006101602035411863)\n",
      "SCV-linear-0.2: 99.15371368505802% (+/- 0.004474483442540483)\n",
      "SCV-linear-0.3: 99.23558771125475% (+/- 0.003515026977485452)\n",
      "SCV-linear-0.4: 99.2628542034755% (+/- 0.003062619363378767)\n",
      "SCV-linear-0.5: 99.30381917264926% (+/- 0.0032537779494845823)\n",
      "SCV-linear-0.6: 99.34476550443941% (+/- 0.0034405415852301552)\n",
      "SCV-linear-0.7: 99.34478414182303% (+/- 0.0037011376799861427)\n",
      "SCV-linear-0.8: 99.34478414182303% (+/- 0.0037011376799861427)\n",
      "SCV-linear-0.9: 99.34480277920666% (+/- 0.003944167917138149)\n",
      "SCV-linear-1.0: 99.34480277920666% (+/- 0.003944167917138149)\n",
      "RidgeClassifier-0.1: 99.04449861710614% (+/- 0.0044840897996343745)\n",
      "RidgeClassifier-0.2: 99.05814118190831% (+/- 0.004544032566178253)\n",
      "RidgeClassifier-0.3: 99.07180238409413% (+/- 0.0046393208404255535)\n",
      "RidgeClassifier-0.4: 99.08544494889628% (+/- 0.0044865102324409545)\n",
      "RidgeClassifier-0.5: 99.09908751369848% (+/- 0.0045749821036690985)\n",
      "RidgeClassifier-0.6: 99.08542631151269% (+/- 0.0044866407127618696)\n",
      "RidgeClassifier-0.7: 99.11273007850066% (+/- 0.004452821838333735)\n",
      "RidgeClassifier-0.8: 99.12639128068645% (+/- 0.004574692652304791)\n",
      "RidgeClassifier-0.9: 99.11274871588427% (+/- 0.004657207420451205)\n",
      "RidgeClassifier-1.0: 99.11274871588427% (+/- 0.004657207420451205)\n",
      "--------\n",
      "Rank=1, Name=RidgeClassifier-1.0, Score=0.9911274871588427 (+/- 0.004657207420451205)\n",
      "Rank=2, Name=RidgeClassifier-0.9, Score=0.9911274871588427 (+/- 0.004657207420451205)\n",
      "Rank=3, Name=RidgeClassifier-0.8, Score=0.9912639128068644 (+/- 0.004574692652304791)\n",
      "Rank=4, Name=RidgeClassifier-0.7, Score=0.9911273007850065 (+/- 0.004452821838333735)\n",
      "Rank=5, Name=RidgeClassifier-0.6, Score=0.9908542631151269 (+/- 0.0044866407127618696)\n",
      "Rank=6, Name=RidgeClassifier-0.5, Score=0.9909908751369848 (+/- 0.0045749821036690985)\n",
      "Rank=7, Name=RidgeClassifier-0.4, Score=0.9908544494889628 (+/- 0.0044865102324409545)\n",
      "Rank=8, Name=RidgeClassifier-0.3, Score=0.9907180238409412 (+/- 0.0046393208404255535)\n",
      "Rank=9, Name=RidgeClassifier-0.2, Score=0.9905814118190831 (+/- 0.004544032566178253)\n",
      "Rank=10, Name=RidgeClassifier-0.1, Score=0.9904449861710614 (+/- 0.0044840897996343745)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bc32e4828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_dataset()\n",
    "models = define_models()\n",
    "results = evaluate_models(X, y, models)\n",
    "summarize_results(results, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to have a ranked list of all models, let's call again the `summarize_results` function but disabling the plotting option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(results, top_n=len(results), plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
